{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0483c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "# imports KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "# imports ColumnTransformer from sklearn.compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# imports Pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# imports StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "file = open('../data/data_prep.save', 'rb')\n",
    "other_sets, test_sets = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/data_prep_wo.save', 'rb')\n",
    "other_sets_wo, test_sets_wo = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7ecaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences G1 G2 G3  \n",
      "0    ...      4        3      4     1     1      3        6  0  0  0  \n",
      "1    ...      5        3      3     1     1      3        4  0  0  0  \n",
      "2    ...      4        3      2     2     3      3       10  0  0  1  \n",
      "3    ...      3        2      2     1     1      5        2  1  1  1  \n",
      "4    ...      4        3      2     1     2      5        4  0  1  1  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ... .. .. ..  \n",
      "390  ...      5        5      4     4     5      4       11  0  0  0  \n",
      "391  ...      2        4      5     3     4      2        3  1  1  1  \n",
      "392  ...      5        5      3     3     3      3        3  1  0  0  \n",
      "393  ...      4        4      1     3     4      5        0  1  1  1  \n",
      "394  ...      3        2      3     3     3      5        5  0  0  0  \n",
      "\n",
      "[395 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# imports matplotlib package\n",
    "import matplotlib\n",
    "# imports pylab from matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "# converts data in the excel file into pandas dataframe\n",
    "df = pd.read_csv(r'/Users/jamesro/Documents/DATA1030-Fall2021/Data-1030-Project/Data/student-mat.csv',sep=';')\n",
    "# converts G3 into binary scale\n",
    "pass_final = df.G3 >= 10\n",
    "fail_final = df.G3 < 10\n",
    "df.loc[pass_final,'G3'] = 1\n",
    "df.loc[fail_final,'G3'] = 0\n",
    "# converts G1 into binary scale\n",
    "pass_first = df.G1 >= 10\n",
    "fail_first = df.G1 < 10\n",
    "df.loc[pass_first,'G1'] = 1\n",
    "df.loc[fail_first,'G1'] = 0\n",
    "# converts G2 into binary scale\n",
    "pass_sec = df.G2 >= 10\n",
    "fail_sec = df.G2 < 10\n",
    "df.loc[pass_sec,'G2'] = 1\n",
    "df.loc[fail_sec,'G2'] = 0\n",
    "# prints dataframe\n",
    "print(df)\n",
    "\n",
    "y = df['G3']\n",
    "X = df.loc[:, df.columns != 'G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5299c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "181     GP   M   16       U     GT3       T     3     3  services     other   \n",
      "194     GP   M   16       U     GT3       T     2     3     other     other   \n",
      "173     GP   F   16       U     GT3       T     1     3   at_home  services   \n",
      "253     GP   M   16       R     GT3       T     2     1     other     other   \n",
      "331     GP   F   17       R     GT3       T     2     4   at_home     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "181  ...      yes      4         2      3     1    2      3        2  1  1  \n",
      "194  ...       no      5         3      3     1    1      3        0  1  1  \n",
      "173  ...      yes      4         3      5     1    1      3        0  0  0  \n",
      "253  ...       no      3         3      2     1    3      3        0  0  0  \n",
      "331  ...      yes      4         4      3     1    1      5        7  1  1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "63      GP   F   16       U     GT3       T     4     3   teacher    health   \n",
      "225     GP   F   18       R     GT3       T     3     1     other     other   \n",
      "383     MS   M   19       R     GT3       T     1     1     other  services   \n",
      "342     GP   M   18       U     LE3       T     3     4  services     other   \n",
      "75      GP   M   15       U     GT3       T     4     3   teacher     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "63   ...       no      3         4      4     2    4      4        2  1  0  \n",
      "225  ...      yes      5         3      3     1    1      4       16  0  0  \n",
      "383  ...       no      4         3      2     1    3      5        0  0  0  \n",
      "342  ...      yes      4         3      3     1    3      5       11  1  1  \n",
      "75   ...       no      4         3      3     2    3      5        6  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "78      GP   M   17       U     GT3       T     2     1     other     other   \n",
      "371     MS   M   18       R     LE3       T     1     2   at_home  services   \n",
      "248     GP   M   18       R     LE3       T     3     3     other  services   \n",
      "55      GP   F   16       U     GT3       A     2     1     other     other   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "78   ...       no      4         5      1     1    1      3        2  0  0  \n",
      "371  ...      yes      4         3      3     2    3      3        3  1  1  \n",
      "248  ...      yes      4         3      3     1    3      5        8  0  0  \n",
      "55   ...      yes      5         3      4     1    1      2        8  0  0  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "[[ 1.          0.          0.         ... -0.33039731  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          0.         ... -0.33039731  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          1.         ... -0.33039731 -1.49357599\n",
      "  -1.40167966]\n",
      " ...\n",
      " [ 1.          0.          1.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]\n",
      " [ 1.          0.          1.         ...  0.39995464  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          0.         ...  1.13030659  0.66953406\n",
      "   0.71342977]]\n",
      "[[ 1.          0.          1.         ...  0.39995464  0.66953406\n",
      "  -1.40167966]\n",
      " [ 1.          0.          1.         ...  0.39995464 -1.49357599\n",
      "  -1.40167966]\n",
      " [ 0.          1.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]\n",
      " ...\n",
      " [ 1.          0.          1.         ... -1.79110121  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]\n",
      " [ 0.          1.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]]\n",
      "[[ 1.          0.          0.         ... -0.33039731 -1.49357599\n",
      "  -1.40167966]\n",
      " [ 0.          1.          0.         ... -0.33039731  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]\n",
      " [ 1.          0.          1.         ...  1.13030659  0.66953406\n",
      "   0.71342977]\n",
      " [ 1.          0.          0.         ...  1.13030659 -1.49357599\n",
      "  -1.40167966]]\n",
      "(252, 58)\n",
      "(64, 58)\n",
      "(79, 58)\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "181     GP   M   16       U     GT3       T     3     3  services     other   \n",
      "194     GP   M   16       U     GT3       T     2     3     other     other   \n",
      "173     GP   F   16       U     GT3       T     1     3   at_home  services   \n",
      "63      GP   F   16       U     GT3       T     4     3   teacher    health   \n",
      "253     GP   M   16       R     GT3       T     2     1     other     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "181  ...      yes      4         2      3     1    2      3        2  1  1  \n",
      "194  ...       no      5         3      3     1    1      3        0  1  1  \n",
      "173  ...      yes      4         3      5     1    1      3        0  0  0  \n",
      "63   ...       no      3         4      4     2    4      4        2  1  0  \n",
      "253  ...       no      3         3      2     1    3      3        0  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "331     GP   F   17       R     GT3       T     2     4   at_home     other   \n",
      "131     GP   F   15       U     GT3       T     1     1   at_home     other   \n",
      "367     MS   F   17       R     GT3       T     1     1     other  services   \n",
      "210     GP   F   19       U     GT3       T     3     3     other     other   \n",
      "104     GP   M   15       U     GT3       A     3     4  services     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "331  ...      yes      4         4      3     1    1      5        7  1  1  \n",
      "131  ...      yes      4         3      3     1    2      4        0  0  0  \n",
      "367  ...      yes      5         2      1     1    2      1        0  0  0  \n",
      "210  ...       no      4         3      3     1    2      3       10  0  0  \n",
      "104  ...       no      5         4      4     1    1      1        0  1  1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "78      GP   M   17       U     GT3       T     2     1     other     other   \n",
      "371     MS   M   18       R     LE3       T     1     2   at_home  services   \n",
      "248     GP   M   18       R     LE3       T     3     3     other  services   \n",
      "55      GP   F   16       U     GT3       A     2     1     other     other   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "78   ...       no      4         5      1     1    1      3        2  0  0  \n",
      "371  ...      yes      4         3      3     2    3      3        3  1  1  \n",
      "248  ...      yes      4         3      3     1    3      5        8  0  0  \n",
      "55   ...      yes      5         3      4     1    1      2        8  0  0  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "[[ 1.          0.          0.         ... -0.33423802  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          0.         ... -0.33423802  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          1.         ... -0.33423802 -1.41841629\n",
      "  -1.36930639]\n",
      " ...\n",
      " [ 1.          0.          1.         ... -0.33423802 -1.41841629\n",
      "  -1.36930639]\n",
      " [ 1.          0.          1.         ...  0.37636886  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          0.         ...  1.08697574  0.70501165\n",
      "   0.73029674]]\n",
      "[[ 1.          0.          1.         ...  1.08697574  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          1.         ...  0.37636886 -1.41841629\n",
      "  -1.36930639]\n",
      " [ 0.          1.          1.         ... -1.75545177 -1.41841629\n",
      "  -1.36930639]\n",
      " ...\n",
      " [ 1.          0.          1.         ...  1.08697574  0.70501165\n",
      "  -1.36930639]\n",
      " [ 0.          1.          1.         ...  0.37636886  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          1.         ...  1.08697574 -1.41841629\n",
      "  -1.36930639]]\n",
      "[[ 1.          0.          0.         ... -0.33423802 -1.41841629\n",
      "  -1.36930639]\n",
      " [ 0.          1.          0.         ... -0.33423802  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          0.         ...  1.08697574 -1.41841629\n",
      "  -1.36930639]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  1.08697574 -1.41841629\n",
      "  -1.36930639]\n",
      " [ 1.          0.          1.         ...  1.08697574  0.70501165\n",
      "   0.73029674]\n",
      " [ 1.          0.          0.         ...  1.08697574 -1.41841629\n",
      "  -1.36930639]]\n",
      "(253, 58)\n",
      "(63, 58)\n",
      "(79, 58)\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob    Fjob  \\\n",
      "181     GP   M   16       U     GT3       T     3     3  services   other   \n",
      "194     GP   M   16       U     GT3       T     2     3     other   other   \n",
      "63      GP   F   16       U     GT3       T     4     3   teacher  health   \n",
      "253     GP   M   16       R     GT3       T     2     1     other   other   \n",
      "225     GP   F   18       R     GT3       T     3     1     other   other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "181  ...      yes      4         2      3     1    2      3        2  1  1  \n",
      "194  ...       no      5         3      3     1    1      3        0  1  1  \n",
      "63   ...       no      3         4      4     2    4      4        2  1  0  \n",
      "253  ...       no      3         3      2     1    3      3        0  0  0  \n",
      "225  ...      yes      5         3      3     1    1      4       16  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "173     GP   F   16       U     GT3       T     1     3  at_home  services   \n",
      "175     GP   M   17       U     LE3       T     4     3  teacher     other   \n",
      "118     GP   M   17       R     GT3       T     1     3    other     other   \n",
      "321     GP   F   17       U     GT3       T     2     2    other     other   \n",
      "281     GP   M   17       U     LE3       A     3     2  teacher  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "173  ...      yes      4         3      5     1    1      3        0  0  0  \n",
      "175  ...       no      4         4      4     4    4      4        4  1  0  \n",
      "118  ...       no      5         2      4     1    4      5       20  0  0  \n",
      "321  ...      yes      4         2      2     1    1      3       12  1  0  \n",
      "281  ...       no      4         4      4     3    4      3       19  1  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "78      GP   M   17       U     GT3       T     2     1     other     other   \n",
      "371     MS   M   18       R     LE3       T     1     2   at_home  services   \n",
      "248     GP   M   18       R     LE3       T     3     3     other  services   \n",
      "55      GP   F   16       U     GT3       A     2     1     other     other   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "78   ...       no      4         5      1     1    1      3        2  0  0  \n",
      "371  ...      yes      4         3      3     2    3      3        3  1  1  \n",
      "248  ...      yes      4         3      3     1    3      5        8  0  0  \n",
      "55   ...      yes      5         3      4     1    1      2        8  0  0  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "[[ 1.          0.          0.         ... -0.41144459  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ... -0.41144459  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          1.         ...  0.29190326  0.72394502\n",
      "  -1.28963479]\n",
      " ...\n",
      " [ 1.          0.          1.         ...  0.99525111 -1.38132037\n",
      "  -1.28963479]\n",
      " [ 1.          0.          1.         ...  0.29190326  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  0.99525111  0.72394502\n",
      "   0.77541332]]\n",
      "[[ 1.          0.          1.         ... -0.41144459 -1.38132037\n",
      "  -1.28963479]\n",
      " [ 1.          0.          0.         ...  0.29190326  0.72394502\n",
      "  -1.28963479]\n",
      " [ 1.          0.          0.         ...  0.99525111 -1.38132037\n",
      "  -1.28963479]\n",
      " ...\n",
      " [ 1.          0.          1.         ...  0.99525111  0.72394502\n",
      "  -1.28963479]\n",
      " [ 1.          0.          0.         ...  0.99525111  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ... -0.41144459  0.72394502\n",
      "   0.77541332]]\n",
      "[[ 1.          0.          0.         ... -0.41144459 -1.38132037\n",
      "  -1.28963479]\n",
      " [ 0.          1.          0.         ... -0.41144459  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  0.99525111 -1.38132037\n",
      "  -1.28963479]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  0.99525111 -1.38132037\n",
      "  -1.28963479]\n",
      " [ 1.          0.          1.         ...  0.99525111  0.72394502\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  0.99525111 -1.38132037\n",
      "  -1.28963479]]\n",
      "(253, 58)\n",
      "(63, 58)\n",
      "(79, 58)\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "194     GP   M   16       U     GT3       T     2     3    other     other   \n",
      "173     GP   F   16       U     GT3       T     1     3  at_home  services   \n",
      "63      GP   F   16       U     GT3       T     4     3  teacher    health   \n",
      "225     GP   F   18       R     GT3       T     3     1    other     other   \n",
      "331     GP   F   17       R     GT3       T     2     4  at_home     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "194  ...       no      5         3      3     1    1      3        0  1  1  \n",
      "173  ...      yes      4         3      5     1    1      3        0  0  0  \n",
      "63   ...       no      3         4      4     2    4      4        2  1  0  \n",
      "225  ...      yes      5         3      3     1    1      4       16  0  0  \n",
      "331  ...      yes      4         4      3     1    1      5        7  1  1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "181     GP   M   16       U     GT3       T     3     3  services     other   \n",
      "253     GP   M   16       R     GT3       T     2     1     other     other   \n",
      "227     GP   M   17       U     LE3       T     2     3  services  services   \n",
      "320     GP   F   17       U     GT3       A     4     3  services  services   \n",
      "368     MS   F   18       U     GT3       T     2     3   at_home  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "181  ...      yes      4         2      3     1    2      3        2  1  1  \n",
      "253  ...       no      3         3      2     1    3      3        0  0  0  \n",
      "227  ...       no      5         3      3     1    3      3        2  1  1  \n",
      "320  ...      yes      5         2      2     1    2      5       23  1  1  \n",
      "368  ...      yes      5         2      3     1    2      4        0  1  1  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "78      GP   M   17       U     GT3       T     2     1     other     other   \n",
      "371     MS   M   18       R     LE3       T     1     2   at_home  services   \n",
      "248     GP   M   18       R     LE3       T     3     3     other  services   \n",
      "55      GP   F   16       U     GT3       A     2     1     other     other   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "78   ...       no      4         5      1     1    1      3        2  0  0  \n",
      "371  ...      yes      4         3      3     2    3      3        3  1  1  \n",
      "248  ...      yes      4         3      3     1    3      5        8  0  0  \n",
      "55   ...      yes      5         3      4     1    1      2        8  0  0  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "[[ 1.          0.          0.         ... -0.43586839  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          1.         ... -0.43586839 -1.36930639\n",
      "  -1.28963479]\n",
      " [ 1.          0.          1.         ...  0.28962307  0.73029674\n",
      "  -1.28963479]\n",
      " ...\n",
      " [ 1.          0.          1.         ...  1.01511454 -1.36930639\n",
      "  -1.28963479]\n",
      " [ 1.          0.          1.         ...  0.28962307  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  1.01511454  0.73029674\n",
      "   0.77541332]]\n",
      "[[ 1.          0.          0.         ... -0.43586839  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ... -0.43586839 -1.36930639\n",
      "  -1.28963479]\n",
      " [ 1.          0.          0.         ... -0.43586839  0.73029674\n",
      "   0.77541332]\n",
      " ...\n",
      " [ 1.          0.          1.         ... -0.43586839 -1.36930639\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ... -1.88685131  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          1.         ... -0.43586839 -1.36930639\n",
      "  -1.28963479]]\n",
      "[[ 1.          0.          0.         ... -0.43586839 -1.36930639\n",
      "  -1.28963479]\n",
      " [ 0.          1.          0.         ... -0.43586839  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  1.01511454 -1.36930639\n",
      "  -1.28963479]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  1.01511454 -1.36930639\n",
      "  -1.28963479]\n",
      " [ 1.          0.          1.         ...  1.01511454  0.73029674\n",
      "   0.77541332]\n",
      " [ 1.          0.          0.         ...  1.01511454 -1.36930639\n",
      "  -1.28963479]]\n",
      "(253, 58)\n",
      "(63, 58)\n",
      "(79, 58)\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "181     GP   M   16       U     GT3       T     3     3  services     other   \n",
      "173     GP   F   16       U     GT3       T     1     3   at_home  services   \n",
      "63      GP   F   16       U     GT3       T     4     3   teacher    health   \n",
      "253     GP   M   16       R     GT3       T     2     1     other     other   \n",
      "225     GP   F   18       R     GT3       T     3     1     other     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "181  ...      yes      4         2      3     1    2      3        2  1  1  \n",
      "173  ...      yes      4         3      5     1    1      3        0  0  0  \n",
      "63   ...       no      3         4      4     2    4      4        2  1  0  \n",
      "253  ...       no      3         3      2     1    3      3        0  0  0  \n",
      "225  ...      yes      5         3      3     1    1      4       16  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "194     GP   M   16       U     GT3       T     2     3     other     other   \n",
      "238     GP   F   17       R     GT3       T     2     1   at_home  services   \n",
      "16      GP   F   16       U     GT3       T     4     4  services  services   \n",
      "66      GP   M   15       U     GT3       A     4     4     other  services   \n",
      "79      GP   F   16       U     GT3       T     3     4   at_home     other   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "194  ...       no      5         3      3     1    1      3        0  1  1  \n",
      "238  ...       no      2         1      1     1    1      3        2  1  1  \n",
      "16   ...       no      3         2      3     1    2      2        6  1  1  \n",
      "66   ...      yes      1         3      3     5    5      3        4  1  1  \n",
      "79   ...       no      2         4      3     1    2      3       12  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "78      GP   M   17       U     GT3       T     2     1     other     other   \n",
      "371     MS   M   18       R     LE3       T     1     2   at_home  services   \n",
      "248     GP   M   18       R     LE3       T     3     3     other  services   \n",
      "55      GP   F   16       U     GT3       A     2     1     other     other   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G2  \n",
      "78   ...       no      4         5      1     1    1      3        2  0  0  \n",
      "371  ...      yes      4         3      3     2    3      3        3  1  1  \n",
      "248  ...      yes      4         3      3     1    3      5        8  0  0  \n",
      "55   ...      yes      5         3      4     1    1      2        8  0  0  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "[[ 1.          0.          0.         ... -0.33363854  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          1.         ... -0.33363854 -1.33424877\n",
      "  -1.31165167]\n",
      " [ 1.          0.          1.         ...  0.3526261   0.74948542\n",
      "  -1.31165167]\n",
      " ...\n",
      " [ 1.          0.          0.         ... -0.33363854  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          1.         ... -0.33363854 -1.33424877\n",
      "  -1.31165167]\n",
      " [ 1.          0.          1.         ...  1.03889073 -1.33424877\n",
      "  -1.31165167]]\n",
      "[[ 1.          0.          0.         ... -0.33363854  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          1.         ... -0.33363854  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          1.         ... -1.01990317  0.74948542\n",
      "   0.76239753]\n",
      " ...\n",
      " [ 1.          0.          1.         ... -0.33363854 -1.33424877\n",
      "  -1.31165167]\n",
      " [ 1.          0.          1.         ...  0.3526261   0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          0.         ...  1.03889073  0.74948542\n",
      "   0.76239753]]\n",
      "[[ 1.          0.          0.         ... -0.33363854 -1.33424877\n",
      "  -1.31165167]\n",
      " [ 0.          1.          0.         ... -0.33363854  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          0.         ...  1.03889073 -1.33424877\n",
      "  -1.31165167]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  1.03889073 -1.33424877\n",
      "  -1.31165167]\n",
      " [ 1.          0.          1.         ...  1.03889073  0.74948542\n",
      "   0.76239753]\n",
      " [ 1.          0.          0.         ...  1.03889073 -1.33424877\n",
      "  -1.31165167]]\n",
      "(253, 58)\n",
      "(63, 58)\n",
      "(79, 58)\n"
     ]
    }
   ],
   "source": [
    "# defines random_state as 42\n",
    "random_state = 42\n",
    "# defines X as all feature columns\n",
    "X = df.loc[:, df.columns != 'G3']\n",
    "# defines y as the target variable G3\n",
    "y = df['G3']\n",
    "\n",
    "# first split to separate out the test set\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print(X_train.head())\n",
    "    print(X_val.head())\n",
    "    print(X_test.head())\n",
    "    onehot_ftrs = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "    minmax_ftrs = ['age','absences']\n",
    "    std_ftrs = ['Medu','Fedu','traveltime','studytime','failures','famrel','freetime','goout','Dalc','Walc','health','G1','G2']\n",
    "\n",
    "    # collects all the encoders\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "            ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "            ('std', StandardScaler(), std_ftrs)\n",
    "            ])\n",
    "\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # transforms X_train into X_train_prep\n",
    "    X_train_prep = clf.fit_transform(X_train)\n",
    "    # transforms X_val into X_val_prep\n",
    "    X_val_prep = clf.transform(X_val)\n",
    "    # transforms X_test into X_test_prep\n",
    "    X_test_prep = clf.transform(X_test)\n",
    "\n",
    "    # prints X_train_prep\n",
    "    print(X_train_prep)\n",
    "    # prints X_val_prep\n",
    "    print(X_val_prep)\n",
    "        # prints X_test_prep\n",
    "    print(X_test_prep)\n",
    "    print(X_train_prep.shape)\n",
    "    print(X_val_prep.shape)\n",
    "    print(X_test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114b55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_ftrs = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "minmax_ftrs = ['age','absences']\n",
    "std_ftrs = ['Medu','Fedu','traveltime','studytime','failures','famrel','freetime','goout','Dalc','Walc','health','G1','G2']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)\n",
    "        ])\n",
    "\n",
    "def MLpipe_KFold_Accu(preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    nr_states = 10\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "\n",
    "    for i in range(nr_states):\n",
    "        \n",
    "        X_other, y_other = other_sets[i]\n",
    "        X_test, y_test = test_sets[i]\n",
    "\n",
    "        kf = KFold(n_splits=5,shuffle=True,random_state=42*i)\n",
    "         \n",
    "        pipe = make_pipeline(preprocessor,ML_algo)\n",
    "        \n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid, scoring = 'accuracy',\n",
    "                        cv=kf, return_train_score = True, n_jobs=-1, verbose=True)\n",
    "        \n",
    "        grid.fit(X_other, y_other)\n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        print('best model parameters:',grid.best_params_)\n",
    "        \n",
    "        print('validation score:',grid.best_score_) # this is the mean validation score over all iterations\n",
    "        # save the model\n",
    "        best_models.append(grid)\n",
    "        # calculate RMSE value for test set\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        test_scores[i] = accuracy_score(y_test,y_test_pred)\n",
    "        print('test score:',test_scores[i])\n",
    "        \n",
    "    return best_models, test_scores, grid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aeec485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    265\n",
      "0    130\n",
      "Name: G3, dtype: int64\n",
      "baseline accuracy score:  0.6708860759493671\n"
     ]
    }
   ],
   "source": [
    "print(df.G3.value_counts())\n",
    "\n",
    "\n",
    "baseline_accuracy = df.G3.value_counts()[1]/len(df)\n",
    "print(\"baseline accuracy score: \", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df35355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9208829365079365\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9146825396825395\n",
      "test score: 0.9367088607594937\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9146329365079365\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9271329365079364\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9209325396825397\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9273809523809524\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9241071428571429\n",
      "test score: 0.8987341772151899\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9113591269841269\n",
      "test score: 0.9493670886075949\n",
      "mean test score:  0.9139240506329113\n",
      "std of test score:  0.01944593860219902\n",
      "95% Confidence Interval:  (0.896878933917396, 0.9309691673484265)\n",
      "standard deviations from baseline:  12.498135454159076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l1_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L1R = LogisticRegression(penalty='l1', solver='saga')\n",
    "l1_best_models, l1_test_scores, l1_grid, l1_X_test, l1_y_test = MLpipe_KFold_Accu(preprocessor, L1R, l1_param_grid)\n",
    "\n",
    "l1_mean = np.mean(l1_test_scores)\n",
    "l1_std = np.std(l1_test_scores)\n",
    "\n",
    "print('mean test score: ',l1_mean)\n",
    "print('std of test score: ',l1_std)\n",
    "print('95% Confidence Interval: ',(l1_mean - 1.96*(l1_std/math.sqrt(5)), l1_mean + 1.96*(l1_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l1_mean - baseline_accuracy)/l1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ce0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8955357142857142\n",
      "test score: 0.9367088607594937\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9146329365079365\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9115079365079364\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9082837301587301\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.92078373015873\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9050099206349206\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.91140873015873\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9210317460317461\n",
      "test score: 0.8987341772151899\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.9146329365079364\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8922619047619047\n",
      "test score: 0.9493670886075949\n",
      "mean test score:  0.911392405063291\n",
      "std of test score:  0.021181266494533557\n",
      "95% Confidence Interval:  (0.8928262063846153, 0.9299586037419667)\n",
      "standard deviations from baseline:  11.354671788676733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l2_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2], \n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L2R = LogisticRegression(penalty='l2', solver='saga')\n",
    "l2_best_models, l2_test_scores, l2_grid, l2_X_test, l2_y_test = MLpipe_KFold_Accu(preprocessor, L2R, l2_param_grid)\n",
    "\n",
    "l2_mean = np.mean(l2_test_scores)\n",
    "l2_std = np.std(l2_test_scores)\n",
    "\n",
    "print('mean test score: ',l2_mean)\n",
    "print('std of test score: ',l2_std)\n",
    "print('95% Confidence Interval: ',(l2_mean - 1.96*(l2_std/math.sqrt(5)), l2_mean + 1.96*(l2_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l2_mean - baseline_accuracy)/l2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd46bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9209325396825397\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9146825396825395\n",
      "test score: 0.9367088607594937\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 1.0, 'logisticregression__l1_ratio': 0.99, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9146329365079365\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9271329365079364\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9209325396825397\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9273809523809524\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9272817460317461\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.9113591269841269\n",
      "test score: 0.9493670886075949\n",
      "mean test score:  0.9126582278481011\n",
      "std of test score:  0.020761037299818656\n",
      "95% Confidence Interval:  (0.9057800864775456, 0.9195363692186567)\n",
      "standard deviations from baseline:  11.645475532229108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "en_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__l1_ratio': [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
    "                 'logisticregression__max_iter': [10000]\n",
    "                 } \n",
    "\n",
    "EN = LogisticRegression(penalty='elasticnet', solver='saga')\n",
    "en_best_models, en_test_scores, en_grid, en_X_test, en_y_test = MLpipe_KFold_Accu(preprocessor, EN, en_param_grid)\n",
    "\n",
    "en_mean = np.mean(en_test_scores)\n",
    "en_std = np.std(en_test_scores)\n",
    "\n",
    "print('mean test score: ',en_mean)\n",
    "print('std of test score: ',en_std)\n",
    "print('95% Confidence Interval: ',(en_mean - 1.96*(en_std/math.sqrt(35)), en_mean + 1.96*(en_std/math.sqrt(35))))\n",
    "print('standard deviations from baseline: ',(en_mean - baseline_accuracy)/en_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451f7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 30, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9240575396825397\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9146825396825395\n",
      "test score: 0.9367088607594937\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.91140873015873\n",
      "test score: 0.9620253164556962\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9271329365079364\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 30, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.9209821428571429\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.9305555555555556\n",
      "test score: 0.8987341772151899\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.9241071428571429\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.9113591269841269\n",
      "test score: 0.9493670886075949\n",
      "mean test score:  0.9139240506329113\n",
      "std of test score:  0.03387110926648013\n",
      "95% Confidence Interval:  (0.8967829043309757, 0.9310651969348468)\n",
      "standard deviations from baseline:  7.17537689041858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math \n",
    "\n",
    "rfc_param_grid = {\n",
    "                   'randomforestclassifier__max_depth': [1, 3, 10, 30, 100],\n",
    "                   'randomforestclassifier__max_features': [0.5,0.75,1.0] \n",
    "                   } \n",
    "\n",
    "ML_algo = RandomForestClassifier()\n",
    "rfc_best_models, rfc_test_scores, rfc_grid, rfc_X_test, rfc_y_test = MLpipe_KFold_Accu(preprocessor, ML_algo, rfc_param_grid)\n",
    "\n",
    "rfc_mean = np.mean(rfc_test_scores)\n",
    "rfc_std = np.std(rfc_test_scores)\n",
    "\n",
    "print('mean test score: ',rfc_mean)\n",
    "print('std of test score: ',rfc_std)\n",
    "print('95% Confidence Interval: ',(rfc_mean - 1.96*(rfc_std/math.sqrt(15)), rfc_mean + 1.96*(rfc_std/math.sqrt(15))))\n",
    "print('standard deviations from baseline: ',(rfc_mean - baseline_accuracy)/rfc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d95aab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9208829365079365\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9146825396825395\n",
      "test score: 0.9367088607594937\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9082341269841269\n",
      "test score: 0.9620253164556962\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9271329365079364\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9177083333333333\n",
      "test score: 0.9240506329113924\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9209325396825397\n",
      "test score: 0.9113924050632911\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9273809523809524\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9241071428571429\n",
      "test score: 0.8987341772151899\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.9113591269841269\n",
      "test score: 0.9493670886075949\n",
      "mean test score:  0.9189873417721518\n",
      "std of test score:  0.02415035952954294\n",
      "95% Confidence Interval:  (0.9119311006151737, 0.9260435829291299)\n",
      "standard deviations from baseline:  10.273191399874788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import math \n",
    "\n",
    "svc_param_grid = {\n",
    "                 'svc__gamma': [1000000, 1000, 1, 0.001],\n",
    "                 'svc__C': [1, 10, 30, 100]\n",
    "                 } \n",
    "\n",
    "SVC = SVC()\n",
    "svc_best_models, svc_test_scores, svc_grid, svc_X_test, svc_y_test = MLpipe_KFold_Accu(preprocessor, SVC, svc_param_grid)\n",
    "\n",
    "svc_mean = np.mean(svc_test_scores)\n",
    "svc_std = np.std(svc_test_scores)\n",
    "\n",
    "print('mean test score: ',svc_mean)\n",
    "print('std of test score: ',svc_std)\n",
    "print('95% Confidence Interval: ',(svc_mean - 1.96*(svc_std/math.sqrt(45)), svc_mean + 1.96*(svc_std/math.sqrt(45))))\n",
    "print('standard deviations from baseline: ',(svc_mean - baseline_accuracy)/svc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3030d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8891865079365079\n",
      "test score: 0.8607594936708861\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8862599206349205\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8863095238095238\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8892857142857142\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.8892361111111111\n",
      "test score: 0.8607594936708861\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8892361111111111\n",
      "test score: 0.8987341772151899\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.8799107142857142\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8828869047619048\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8955853174603174\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.8764384920634921\n",
      "test score: 0.9367088607594937\n",
      "mean test score:  0.8848101265822785\n",
      "std of test score:  0.02076103729981863\n",
      "95% Confidence Interval:  (0.8704234617282933, 0.8991967914362637)\n",
      "standard deviations from baseline:  10.304111858359807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math \n",
    "\n",
    "knn_param_grid = {\n",
    "                   'kneighborsclassifier__n_neighbors': [1, 10, 30, 100], \n",
    "                   'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "                   } \n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "knn_best_models, knn_test_scores, knn_grid, knn_X_test, knn_y_test = MLpipe_KFold_Accu(preprocessor, KNN, knn_param_grid)\n",
    "\n",
    "knn_mean = np.mean(knn_test_scores)\n",
    "knn_std = np.std(knn_test_scores)\n",
    "\n",
    "print('mean test score: ',knn_mean)\n",
    "print('std of test score: ',knn_std)\n",
    "print('95% Confidence Interval: ',(knn_mean - 1.96*(knn_std/math.sqrt(8)), knn_mean + 1.96*(knn_std/math.sqrt(8))))\n",
    "print('standard deviations from baseline: ',(knn_mean - baseline_accuracy)/knn_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d534a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = [\"Lasso\", \"Ridge\", \"EN\", \"RF\", \"SVC\", \"KNN\"]\n",
    "mean_scores = [l1_mean, l2_mean, en_mean, rfc_mean, svc_mean, knn_mean]\n",
    "stdev_scores = [l1_std, l2_std, en_std, rfc_std, svc_std, knn_std]\n",
    "\n",
    "plt.bar(model_name, mean_scores, yerr=stdev_scores, capsize=2)\n",
    "plt.ylim([0.7,1])\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"ML Models VS Accuracy Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('../figures/mlmodels_accu.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35553dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../Results/l1_models_tuned.save', 'wb')\n",
    "pickle.dump(l1_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/l2_models_tuned.save', 'wb')\n",
    "pickle.dump(l2_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/en_models_tuned.save', 'wb')\n",
    "pickle.dump(l1_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/rfc_models_tuned.save', 'wb')\n",
    "pickle.dump(rfc_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/svc_models_tuned.save', 'wb')\n",
    "pickle.dump(svc_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/knn_models_tuned.save', 'wb')\n",
    "pickle.dump(knn_best_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/l1_test_scores.save', 'wb')\n",
    "pickle.dump(l1_test_scores, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/l2_test_scores.save', 'wb')\n",
    "pickle.dump(l2_test_scores, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/en_test_scores.save', 'wb')\n",
    "pickle.dump(en_test_scores, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/rfc_test_scores.save', 'wb')\n",
    "pickle.dump(rfc_test_scores, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/svc_test_scores.save', 'wb')\n",
    "pickle.dump(svc_test_scores, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../Results/knn_test_scores.save', 'wb')\n",
    "pickle.dump(knn_test_scores, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
