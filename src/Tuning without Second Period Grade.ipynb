{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7534694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "# imports KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "# imports ColumnTransformer from sklearn.compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# imports Pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# imports StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "file = open('../data/data_prep_wo.save', 'rb')\n",
    "other_sets_wo, test_sets_wo = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2840a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... romantic famrel  freetime  goout  Dalc Walc health absences G1 G3  \n",
      "0    ...       no      4         3      4     1    1      3        6  0  0  \n",
      "1    ...       no      5         3      3     1    1      3        4  0  0  \n",
      "2    ...       no      4         3      2     2    3      3       10  0  1  \n",
      "3    ...      yes      3         2      2     1    1      5        2  1  1  \n",
      "4    ...       no      4         3      2     1    2      5        4  0  1  \n",
      "..   ...      ...    ...       ...    ...   ...  ...    ...      ... .. ..  \n",
      "390  ...       no      5         5      4     4    5      4       11  0  0  \n",
      "391  ...       no      2         4      5     3    4      2        3  1  1  \n",
      "392  ...       no      5         5      3     3    3      3        3  1  0  \n",
      "393  ...       no      4         4      1     3    4      5        0  1  1  \n",
      "394  ...       no      3         2      3     3    3      5        5  0  0  \n",
      "\n",
      "[395 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# converts data in the excel file into pandas dataframe\n",
    "dff = pd.read_csv(r'/Users/jamesro/Documents/DATA1030-Fall2021/Data-1030-Project/Data/student-mat.csv',sep=';')\n",
    "# converts G3 into binary scale\n",
    "pass_final = dff.G3 >= 10\n",
    "fail_final = dff.G3 < 10\n",
    "dff.loc[pass_final,'G3'] = 1\n",
    "dff.loc[fail_final,'G3'] = 0\n",
    "# converts G1 into binary scale\n",
    "pass_first = dff.G1 >= 10\n",
    "fail_first = dff.G1 < 10\n",
    "dff.loc[pass_first,'G1'] = 1\n",
    "dff.loc[fail_first,'G1'] = 0\n",
    "# converts G2 into binary scale\n",
    "pass_sec = dff.G2 >= 10\n",
    "fail_sec = dff.G2 < 10\n",
    "dff.loc[pass_sec,'G2'] = 1\n",
    "dff.loc[fail_sec,'G2'] = 0\n",
    "# prints dataframe\n",
    "\n",
    "dff.drop('G2', axis=1, inplace=True)\n",
    "print(dff)\n",
    "yy = dff['G3']\n",
    "XX = dff.loc[:, dff.columns != 'G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969d3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas package\n",
    "import pandas as pd\n",
    "# imports numpy package\n",
    "import numpy as np\n",
    "# imports matplotlib package\n",
    "import matplotlib\n",
    "# imports pylab from matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "# imports train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "# imports KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "# imports ColumnTransformer from sklearn.compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# imports Pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# imports StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "onehot_ftrs = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "minmax_ftrs = ['age','absences']\n",
    "std_ftrs = ['Medu','Fedu','traveltime','studytime','failures','famrel','freetime','goout','Dalc','Walc','health', 'G1']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)\n",
    "        ])\n",
    "\n",
    "def MLpipe_KFold_Accu(preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    nr_states = 10\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "\n",
    "    for i in range(nr_states):\n",
    "        \n",
    "        X_other, y_other = other_sets_wo[i]\n",
    "        X_test, y_test = test_sets_wo[i]\n",
    "\n",
    "        kf = KFold(n_splits=5,shuffle=True,random_state=42*i)\n",
    "         \n",
    "        pipe = make_pipeline(preprocessor,ML_algo)\n",
    "        \n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid, scoring = 'accuracy',\n",
    "                        cv=kf, return_train_score = True, n_jobs=-1, verbose=True)\n",
    "        \n",
    "        grid.fit(X_other, y_other)\n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        print('best model parameters:',grid.best_params_)\n",
    "        \n",
    "        print('validation score:',grid.best_score_) # this is the mean validation score over all iterations\n",
    "        # save the model\n",
    "        best_models.append(grid)\n",
    "        # calculate RMSE value for test set\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        test_scores[i] = accuracy_score(y_test,y_test_pred)\n",
    "        print('test score:',test_scores[i])\n",
    "        \n",
    "    return best_models, test_scores, grid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b25808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    265\n",
      "0    130\n",
      "Name: G3, dtype: int64\n",
      "baseline accuracy score:  0.6708860759493671\n"
     ]
    }
   ],
   "source": [
    "print(dff.G3.value_counts())\n",
    "\n",
    "\n",
    "baseline_accuracy = dff.G3.value_counts()[1]/len(dff)\n",
    "print(\"baseline accuracy score: \", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6cc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8290178571428571\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8356646825396826\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8419642857142857\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8417658730158729\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8385912698412697\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8418650793650795\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.82921626984127\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8354166666666666\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8449404761904761\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8384920634920636\n",
      "test score: 0.8354430379746836\n",
      "mean test score:  0.8367088607594937\n",
      "std of test score:  0.021518987341772145\n",
      "95% Confidence Interval:  (0.817846636706255, 0.8555710848127324)\n",
      "standard deviations from baseline:  7.705882352941178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l1_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L1R = LogisticRegression(penalty='l1', solver='saga')\n",
    "l1_best_models, l1_test_scores, l1_grid, l1_X_test, l1_y_test = MLpipe_KFold_Accu(preprocessor, L1R, l1_param_grid)\n",
    "\n",
    "l1_mean = np.mean(l1_test_scores)\n",
    "l1_std = np.std(l1_test_scores)\n",
    "\n",
    "print('mean test score: ',l1_mean)\n",
    "print('std of test score: ',l1_std)\n",
    "print('95% Confidence Interval: ',(l1_mean - 1.96*(l1_std/math.sqrt(5)), l1_mean + 1.96*(l1_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l1_mean - baseline_accuracy)/l1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fb520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.810218253968254\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8261904761904763\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8324404761904761\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8292162698412697\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8162698412698413\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8355158730158729\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.816517857142857\n",
      "test score: 0.8860759493670886\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8194444444444443\n",
      "test score: 0.7974683544303798\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8290674603174603\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.8289186507936508\n",
      "test score: 0.8354430379746836\n",
      "mean test score:  0.8354430379746836\n",
      "std of test score:  0.023340618879222473\n",
      "95% Confidence Interval:  (0.8149840834779478, 0.8559019924714193)\n",
      "standard deviations from baseline:  7.050239879106333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l2_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2], \n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L2R = LogisticRegression(penalty='l2', solver='saga')\n",
    "l2_best_models, l2_test_scores, l2_grid, l2_X_test, l2_y_test = MLpipe_KFold_Accu(preprocessor, L2R, l2_param_grid)\n",
    "\n",
    "l2_mean = np.mean(l2_test_scores)\n",
    "l2_std = np.std(l2_test_scores)\n",
    "\n",
    "print('mean test score: ',l2_mean)\n",
    "print('std of test score: ',l2_std)\n",
    "print('95% Confidence Interval: ',(l2_mean - 1.96*(l2_std/math.sqrt(5)), l2_mean + 1.96*(l2_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l2_mean - baseline_accuracy)/l2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50eb226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8354166666666666\n",
      "test score: 0.8607594936708861\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.1, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8388392857142858\n",
      "test score: 0.8607594936708861\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.848313492063492\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8417658730158729\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8480158730158731\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8481646825396826\n",
      "test score: 0.7974683544303798\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.82921626984127\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8385912698412697\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8481150793650792\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.8416666666666666\n",
      "test score: 0.8354430379746836\n",
      "mean test score:  0.8379746835443038\n",
      "std of test score:  0.021778038650740815\n",
      "95% Confidence Interval:  (0.83075960915038, 0.8451897579382276)\n",
      "standard deviations from baseline:  7.672344157092077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "en_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__l1_ratio': [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
    "                 'logisticregression__max_iter': [10000]\n",
    "                 } \n",
    "\n",
    "EN = LogisticRegression(penalty='elasticnet', solver='saga')\n",
    "en_best_models, en_test_scores, en_grid, en_X_test, en_y_test = MLpipe_KFold_Accu(preprocessor, EN, en_param_grid)\n",
    "\n",
    "en_mean = np.mean(en_test_scores)\n",
    "en_std = np.std(en_test_scores)\n",
    "\n",
    "print('mean test score: ',en_mean)\n",
    "print('std of test score: ',en_std)\n",
    "print('95% Confidence Interval: ',(en_mean - 1.96*(en_std/math.sqrt(35)), en_mean + 1.96*(en_std/math.sqrt(35))))\n",
    "print('standard deviations from baseline: ',(en_mean - baseline_accuracy)/en_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07c50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.8321924603174603\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.8356646825396826\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.8419642857142857\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.844890873015873\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.8385912698412697\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.851388888888889\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.82921626984127\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.8418154761904763\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.8449404761904761\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.8384920634920636\n",
      "test score: 0.8354430379746836\n",
      "mean test score:  0.8341772151898734\n",
      "std of test score:  0.018299787714937916\n",
      "95% Confidence Interval:  (0.8249162448434862, 0.8434381855362606)\n",
      "standard deviations from baseline:  8.923116583872366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math \n",
    "\n",
    "rfc_param_grid = {\n",
    "                   'randomforestclassifier__max_depth': [1, 3, 10, 30, 100],\n",
    "                   'randomforestclassifier__max_features': [0.5,0.75,1.0] \n",
    "                   } \n",
    "\n",
    "ML_algo = RandomForestClassifier()\n",
    "rfc_best_models, rfc_test_scores, rfc_grid, rfc_X_test, rfc_y_test = MLpipe_KFold_Accu(preprocessor, ML_algo, rfc_param_grid)\n",
    "\n",
    "rfc_mean = np.mean(rfc_test_scores)\n",
    "rfc_std = np.std(rfc_test_scores)\n",
    "\n",
    "print('mean test score: ',rfc_mean)\n",
    "print('std of test score: ',rfc_std)\n",
    "print('95% Confidence Interval: ',(rfc_mean - 1.96*(rfc_std/math.sqrt(15)), rfc_mean + 1.96*(rfc_std/math.sqrt(15))))\n",
    "print('standard deviations from baseline: ',(rfc_mean - baseline_accuracy)/rfc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8396093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8290178571428571\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8356646825396826\n",
      "test score: 0.8481012658227848\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8419642857142857\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8417658730158729\n",
      "test score: 0.8227848101265823\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8385912698412697\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8450396825396826\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 100, 'svc__gamma': 0.001}\n",
      "validation score: 0.8323908730158731\n",
      "test score: 0.8734177215189873\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8385912698412697\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8449404761904761\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.8384920634920636\n",
      "test score: 0.8354430379746836\n",
      "mean test score:  0.8367088607594937\n",
      "std of test score:  0.021518987341772145\n",
      "95% Confidence Interval:  (0.8304214527417475, 0.8429962687772399)\n",
      "standard deviations from baseline:  7.705882352941178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import math \n",
    "\n",
    "svc_param_grid = {\n",
    "                 'svc__gamma': [1000000, 1000, 1, 0.001],\n",
    "                 'svc__C': [1, 10, 30, 100]\n",
    "                 } \n",
    "\n",
    "SVC = SVC()\n",
    "svc_best_models, svc_test_scores, svc_grid, svc_X_test, svc_y_test = MLpipe_KFold_Accu(preprocessor, SVC, svc_param_grid)\n",
    "\n",
    "svc_mean = np.mean(svc_test_scores)\n",
    "svc_std = np.std(svc_test_scores)\n",
    "\n",
    "print('mean test score: ',svc_mean)\n",
    "print('std of test score: ',svc_std)\n",
    "print('95% Confidence Interval: ',(svc_mean - 1.96*(svc_std/math.sqrt(45)), svc_mean + 1.96*(svc_std/math.sqrt(45))))\n",
    "print('standard deviations from baseline: ',(svc_mean - baseline_accuracy)/svc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a58dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7846230158730159\n",
      "test score: 0.7721518987341772\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8007936507936508\n",
      "test score: 0.7848101265822784\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7975198412698412\n",
      "test score: 0.7974683544303798\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7911706349206348\n",
      "test score: 0.7974683544303798\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7912698412698412\n",
      "test score: 0.8354430379746836\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7973214285714285\n",
      "test score: 0.7974683544303798\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.7689980158730159\n",
      "test score: 0.7721518987341772\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7848710317460317\n",
      "test score: 0.7721518987341772\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7847718253968254\n",
      "test score: 0.810126582278481\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.8067460317460317\n",
      "test score: 0.7848101265822784\n",
      "mean test score:  0.7924050632911392\n",
      "std of test score:  0.01894510069252629\n",
      "95% Confidence Interval:  (0.7792767783045909, 0.8055333482776876)\n",
      "standard deviations from baseline:  6.414269805898183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math \n",
    "\n",
    "knn_param_grid = {\n",
    "                   'kneighborsclassifier__n_neighbors': [1, 10, 30, 100], \n",
    "                   'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "                   } \n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "knn_best_models, knn_test_scores, knn_grid, knn_X_test, knn_y_test = MLpipe_KFold_Accu(preprocessor, KNN, knn_param_grid)\n",
    "\n",
    "knn_mean = np.mean(knn_test_scores)\n",
    "knn_std = np.std(knn_test_scores)\n",
    "\n",
    "print('mean test score: ',knn_mean)\n",
    "print('std of test score: ',knn_std)\n",
    "print('95% Confidence Interval: ',(knn_mean - 1.96*(knn_std/math.sqrt(8)), knn_mean + 1.96*(knn_std/math.sqrt(8))))\n",
    "print('standard deviations from baseline: ',(knn_mean - baseline_accuracy)/knn_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f630e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = [\"Lasso\", \"Ridge\", \"EN\", \"RF\", \"SVC\", \"KNN\"]\n",
    "mean_scores = [l1_mean, l2_mean, en_mean, rfc_mean, svc_mean, knn_mean]\n",
    "stdev_scores = [l1_std, l2_std, en_std, rfc_std, svc_std, knn_std]\n",
    "\n",
    "plt.bar(model_name, mean_scores, yerr=stdev_scores, capsize=2)\n",
    "plt.ylim([0.6,0.9])\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"ML Models VS Accuracy Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('../figures/mlmodels_accu_wo.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b47f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
