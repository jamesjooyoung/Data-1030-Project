{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048082f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "# imports KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "# imports ColumnTransformer from sklearn.compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# imports Pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# imports StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "file = open('../data/data_prep_gt.save', 'rb')\n",
    "other_sets_gt, test_sets_gt = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bb5714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
      "0    ...       no       no       4         3      4    1    1      3        6   \n",
      "1    ...      yes       no       5         3      3    1    1      3        4   \n",
      "2    ...      yes       no       4         3      2    2    3      3       10   \n",
      "3    ...      yes      yes       3         2      2    1    1      5        2   \n",
      "4    ...       no       no       4         3      2    1    2      5        4   \n",
      "..   ...      ...      ...     ...       ...    ...  ...  ...    ...      ...   \n",
      "390  ...       no       no       5         5      4    4    5      4       11   \n",
      "391  ...      yes       no       2         4      5    3    4      2        3   \n",
      "392  ...       no       no       5         5      3    3    3      3        3   \n",
      "393  ...      yes       no       4         4      1    3    4      5        0   \n",
      "394  ...      yes       no       3         2      3    3    3      5        5   \n",
      "\n",
      "    G3  \n",
      "0    0  \n",
      "1    0  \n",
      "2    1  \n",
      "3    1  \n",
      "4    1  \n",
      "..  ..  \n",
      "390  0  \n",
      "391  1  \n",
      "392  0  \n",
      "393  1  \n",
      "394  0  \n",
      "\n",
      "[395 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# converts data in the excel file into pandas dataframe\n",
    "dfff = pd.read_csv(r'/Users/jamesro/Documents/DATA1030-Fall2021/Data-1030-Project/Data/student-mat.csv',sep=';')\n",
    "# converts G3 into binary scale\n",
    "pass_final = dfff.G3 >= 10\n",
    "fail_final = dfff.G3 < 10\n",
    "dfff.loc[pass_final,'G3'] = 1\n",
    "dfff.loc[fail_final,'G3'] = 0\n",
    "# drop G1 and G2 features\n",
    "dfff.drop('G1', axis=1, inplace=True)\n",
    "dfff.drop('G2', axis=1, inplace=True)\n",
    "print(dfff)\n",
    "yyy = dfff['G3']\n",
    "XXX = dfff.loc[:, dfff.columns != 'G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7bba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas package\n",
    "import pandas as pd\n",
    "# imports numpy package\n",
    "import numpy as np\n",
    "# imports matplotlib package\n",
    "import matplotlib\n",
    "# imports pylab from matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "# imports train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "# imports KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "# imports ColumnTransformer from sklearn.compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# imports Pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# imports StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "onehot_ftrs = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "minmax_ftrs = ['age','absences']\n",
    "std_ftrs = ['Medu','Fedu','traveltime','studytime','failures','famrel','freetime','goout','Dalc','Walc','health']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)\n",
    "        ])\n",
    "\n",
    "def MLpipe_KFold_Accu(preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    nr_states = 10\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "\n",
    "    for i in range(nr_states):\n",
    "        \n",
    "        X_other, y_other = other_sets_gt[i]\n",
    "        X_test, y_test = test_sets_gt[i]\n",
    "\n",
    "        kf = KFold(n_splits=4,shuffle=True,random_state=42*i)\n",
    "         \n",
    "        pipe = make_pipeline(preprocessor,ML_algo)\n",
    "        \n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid, scoring = 'accuracy',\n",
    "                        cv=kf, return_train_score = True, n_jobs=-1, verbose=True)\n",
    "        \n",
    "        grid.fit(X_other, y_other)\n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        print('best model parameters:',grid.best_params_)\n",
    "        \n",
    "        print('validation score:',grid.best_score_) # this is the mean validation score over all iterations\n",
    "        # save the model\n",
    "        best_models.append(grid)\n",
    "        # calculate RMSE value for test set\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        test_scores[i] = accuracy_score(y_test,y_test_pred)\n",
    "        print('test score:',test_scores[i])\n",
    "        \n",
    "    return best_models, test_scores, grid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024e26d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    265\n",
      "0    130\n",
      "Name: G3, dtype: int64\n",
      "baseline accuracy score:  0.6708860759493671\n"
     ]
    }
   ],
   "source": [
    "print(dfff.G3.value_counts())\n",
    "\n",
    "\n",
    "baseline_accuracy = dfff.G3.value_counts()[1]/len(dfff)\n",
    "print(\"baseline accuracy score: \", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2a3f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7278481012658228\n",
      "test score: 0.6708860759493671\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7183544303797468\n",
      "test score: 0.7215189873417721\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7215189873417722\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7151898734177216\n",
      "test score: 0.7341772151898734\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.6930379746835443\n",
      "test score: 0.8227848101265823\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7120253164556962\n",
      "test score: 0.759493670886076\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7183544303797469\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7215189873417722\n",
      "test score: 0.6582278481012658\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7088607594936709\n",
      "test score: 0.7848101265822784\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.7721518987341772\n",
      "mean test score:  0.7329113924050632\n",
      "std of test score:  0.04949674631903078\n",
      "95% Confidence Interval:  (0.6895255813467724, 0.776297203463354)\n",
      "standard deviations from baseline:  1.2531190647545303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l1_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L1R = LogisticRegression(penalty='l1', solver='saga')\n",
    "l1_best_models, l1_test_scores, l1_grid, l1_X_test, l1_y_test = MLpipe_KFold_Accu(preprocessor, L1R, l1_param_grid)\n",
    "\n",
    "l1_mean = np.mean(l1_test_scores)\n",
    "l1_std = np.std(l1_test_scores)\n",
    "\n",
    "print('mean test score: ',l1_mean)\n",
    "print('std of test score: ',l1_std)\n",
    "print('95% Confidence Interval: ',(l1_mean - 1.96*(l1_std/math.sqrt(5)), l1_mean + 1.96*(l1_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l1_mean - baseline_accuracy)/l1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce390193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.6708860759493671\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.6582278481012658\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.699367088607595\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7025316455696202\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.6740506329113924\n",
      "test score: 0.7974683544303798\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7120253164556962\n",
      "test score: 0.7341772151898734\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7088607594936709\n",
      "test score: 0.7468354430379747\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.7025316455696203\n",
      "test score: 0.620253164556962\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.6835443037974683\n",
      "test score: 0.759493670886076\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000000.0}\n",
      "validation score: 0.6898734177215189\n",
      "test score: 0.7341772151898734\n",
      "mean test score:  0.7126582278481013\n",
      "std of test score:  0.05001201586110991\n",
      "95% Confidence Interval:  (0.6688207631224634, 0.7564956925737392)\n",
      "standard deviations from baseline:  0.8352423148617135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "l2_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2], \n",
    "                 'logisticregression__max_iter': [10e5]\n",
    "                 } \n",
    "\n",
    "L2R = LogisticRegression(penalty='l2', solver='saga')\n",
    "l2_best_models, l2_test_scores, l2_grid, l2_X_test, l2_y_test = MLpipe_KFold_Accu(preprocessor, L2R, l2_param_grid)\n",
    "\n",
    "l2_mean = np.mean(l2_test_scores)\n",
    "l2_std = np.std(l2_test_scores)\n",
    "\n",
    "print('mean test score: ',l2_mean)\n",
    "print('std of test score: ',l2_std)\n",
    "print('95% Confidence Interval: ',(l2_mean - 1.96*(l2_std/math.sqrt(5)), l2_mean + 1.96*(l2_std/math.sqrt(5))))\n",
    "print('standard deviations from baseline: ',(l2_mean - baseline_accuracy)/l2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7cec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7436708860759493\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7310126582278481\n",
      "test score: 0.7341772151898734\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7373417721518987\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.25, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7183544303797468\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.6993670886075949\n",
      "test score: 0.7848101265822784\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.9, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7120253164556962\n",
      "test score: 0.759493670886076\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.99, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7183544303797469\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7341772151898734\n",
      "test score: 0.6582278481012658\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.5, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7183544303797468\n",
      "test score: 0.7468354430379747\n",
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n",
      "best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.75, 'logisticregression__max_iter': 10000}\n",
      "validation score: 0.7120253164556962\n",
      "test score: 0.7721518987341772\n",
      "mean test score:  0.7278481012658229\n",
      "std of test score:  0.03679605532594591\n",
      "95% Confidence Interval:  (0.7156575509211709, 0.7400386516104749)\n",
      "standard deviations from baseline:  1.5480470613460102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math \n",
    "\n",
    "en_param_grid = {\n",
    "                 'logisticregression__C': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                 'logisticregression__l1_ratio': [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
    "                 'logisticregression__max_iter': [10000]\n",
    "                 } \n",
    "\n",
    "EN = LogisticRegression(penalty='elasticnet', solver='saga')\n",
    "en_best_models, en_test_scores, en_grid, en_X_test, en_y_test = MLpipe_KFold_Accu(preprocessor, EN, en_param_grid)\n",
    "\n",
    "en_mean = np.mean(en_test_scores)\n",
    "en_std = np.std(en_test_scores)\n",
    "\n",
    "print('mean test score: ',en_mean)\n",
    "print('std of test score: ',en_std)\n",
    "print('95% Confidence Interval: ',(en_mean - 1.96*(en_std/math.sqrt(35)), en_mean + 1.96*(en_std/math.sqrt(35))))\n",
    "print('standard deviations from baseline: ',(en_mean - baseline_accuracy)/en_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b2e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.7405063291139241\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.7278481012658228\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.7278481012658229\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.7405063291139241\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.6962025316455696\n",
      "test score: 0.759493670886076\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.7025316455696203\n",
      "test score: 0.759493670886076\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 30, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.7278481012658229\n",
      "test score: 0.7215189873417721\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.7246835443037976\n",
      "test score: 0.6708860759493671\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 30, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.7088607594936709\n",
      "test score: 0.7468354430379747\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "best model parameters: {'randomforestclassifier__max_depth': 100, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.759493670886076\n",
      "mean test score:  0.7202531645569621\n",
      "std of test score:  0.03174667393413785\n",
      "95% Confidence Interval:  (0.7041871308695614, 0.7363191982443628)\n",
      "standard deviations from baseline:  1.5550318345163563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math \n",
    "\n",
    "rfc_param_grid = {\n",
    "                   'randomforestclassifier__max_depth': [1, 3, 10, 30, 100],\n",
    "                   'randomforestclassifier__max_features': [0.5,0.75,1.0] \n",
    "                   } \n",
    "\n",
    "ML_algo = RandomForestClassifier()\n",
    "rfc_best_models, rfc_test_scores, rfc_grid, rfc_X_test, rfc_y_test = MLpipe_KFold_Accu(preprocessor, ML_algo, rfc_param_grid)\n",
    "\n",
    "rfc_mean = np.mean(rfc_test_scores)\n",
    "rfc_std = np.std(rfc_test_scores)\n",
    "\n",
    "print('mean test score: ',rfc_mean)\n",
    "print('std of test score: ',rfc_std)\n",
    "print('95% Confidence Interval: ',(rfc_mean - 1.96*(rfc_std/math.sqrt(15)), rfc_mean + 1.96*(rfc_std/math.sqrt(15))))\n",
    "print('standard deviations from baseline: ',(rfc_mean - baseline_accuracy)/rfc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce29d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7278481012658228\n",
      "test score: 0.6835443037974683\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 30, 'svc__gamma': 0.001}\n",
      "validation score: 0.7215189873417721\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7278481012658228\n",
      "test score: 0.6962025316455697\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7151898734177216\n",
      "test score: 0.7341772151898734\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.6930379746835442\n",
      "test score: 0.810126582278481\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7151898734177216\n",
      "test score: 0.7468354430379747\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7183544303797469\n",
      "test score: 0.7215189873417721\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 30, 'svc__gamma': 0.001}\n",
      "validation score: 0.7215189873417722\n",
      "test score: 0.6708860759493671\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 30, 'svc__gamma': 0.001}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.7341772151898734\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "best model parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "validation score: 0.7056962025316456\n",
      "test score: 0.759493670886076\n",
      "mean test score:  0.7265822784810126\n",
      "std of test score:  0.03847768140144472\n",
      "95% Confidence Interval:  (0.7153398868802653, 0.73782467008176)\n",
      "standard deviations from baseline:  1.4474937289114909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import math \n",
    "\n",
    "svc_param_grid = {\n",
    "                 'svc__gamma': [1000000, 1000, 1, 0.001],\n",
    "                 'svc__C': [1, 10, 30, 100]\n",
    "                 } \n",
    "\n",
    "SVC = SVC()\n",
    "svc_best_models, svc_test_scores, svc_grid, svc_X_test, svc_y_test = MLpipe_KFold_Accu(preprocessor, SVC, svc_param_grid)\n",
    "\n",
    "svc_mean = np.mean(svc_test_scores)\n",
    "svc_std = np.std(svc_test_scores)\n",
    "\n",
    "print('mean test score: ',svc_mean)\n",
    "print('std of test score: ',svc_std)\n",
    "print('95% Confidence Interval: ',(svc_mean - 1.96*(svc_std/math.sqrt(45)), svc_mean + 1.96*(svc_std/math.sqrt(45))))\n",
    "print('standard deviations from baseline: ',(svc_mean - baseline_accuracy)/svc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b887d0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7151898734177216\n",
      "test score: 0.6835443037974683\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7151898734177216\n",
      "test score: 0.6835443037974683\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.699367088607595\n",
      "test score: 0.6835443037974683\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.6930379746835442\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.6835443037974683\n",
      "test score: 0.8227848101265823\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.7088607594936709\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.7120253164556962\n",
      "test score: 0.7088607594936709\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 100, 'kneighborsclassifier__weights': 'uniform'}\n",
      "validation score: 0.7025316455696203\n",
      "test score: 0.5443037974683544\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.6772151898734177\n",
      "test score: 0.7468354430379747\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "best model parameters: {'kneighborsclassifier__n_neighbors': 30, 'kneighborsclassifier__weights': 'distance'}\n",
      "validation score: 0.6930379746835442\n",
      "test score: 0.7468354430379747\n",
      "mean test score:  0.7037974683544304\n",
      "std of test score:  0.06678939725707808\n",
      "95% Confidence Interval:  (0.6575147773568251, 0.7500801593520356)\n",
      "standard deviations from baseline:  0.49276372832628645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math \n",
    "\n",
    "knn_param_grid = {\n",
    "                   'kneighborsclassifier__n_neighbors': [1, 10, 30, 100], \n",
    "                   'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "                   } \n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "knn_best_models, knn_test_scores, knn_grid, knn_X_test, knn_y_test = MLpipe_KFold_Accu(preprocessor, KNN, knn_param_grid)\n",
    "\n",
    "knn_mean = np.mean(knn_test_scores)\n",
    "knn_std = np.std(knn_test_scores)\n",
    "\n",
    "print('mean test score: ',knn_mean)\n",
    "print('std of test score: ',knn_std)\n",
    "print('95% Confidence Interval: ',(knn_mean - 1.96*(knn_std/math.sqrt(8)), knn_mean + 1.96*(knn_std/math.sqrt(8))))\n",
    "print('standard deviations from baseline: ',(knn_mean - baseline_accuracy)/knn_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08363d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = [\"Lasso\", \"Ridge\", \"EN\", \"RF\", \"SVC\", \"KNN\"]\n",
    "mean_scores = [l1_mean, l2_mean, en_mean, rfc_mean, svc_mean, knn_mean]\n",
    "stdev_scores = [l1_std, l2_std, en_std, rfc_std, svc_std, knn_std]\n",
    "\n",
    "plt.bar(model_name, mean_scores, yerr=stdev_scores, capsize=2)\n",
    "plt.ylim([0.4,0.8])\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.title(\"ML Models VS Accuracy Score\")\n",
    "plt.savefig('../figures/mlmodels_accu_gt.jpg', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
